{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal of notebook: Create a comprehensive metadata file, using an REL606 reference genome annotated using E. coli K12 protein list.\n",
    "\n",
    "#### Rationale\n",
    "All the functional genomics tools, such as gene ontology and KEGG use E. coli K12 as the reference E. coli strain. Moreover, the default REL 606 genbank file isn't super well annotated, and names can differ from those in E. coli K12 (NC_12967.gb). So I used prokka to reannotate the REL606 genome, using E. coli K12 as a protein reference. This ensures that gene names and uniprot IDs are consistent with E. coli K12 and the functional genomics tools.\n",
    "\n",
    "#### Approach\n",
    "The current approach is to make a list of genomic coordinates in the REL606 genome for genes which are not pseudogenes, or genes related to insertion sequences and search for those coordinates in the gbk file outputted by prokka with the K12 annotations as a starting point. If at least one of the coordinates in the prokka output gbk file is present in the original gbk file, then include in the gene list\n",
    "\n",
    "#### Panther DB\n",
    "I'm using the Panther database as for my gene ontology analysis (geneontology.org). To ensure that as many genes as possible are included, I'm going to iterate through the prokka annotated genome, and identify genes where either the name or the uniprot ID matches something in the panther database (which I have downloaded)\n",
    "\n",
    "#### Output\n",
    "- Final metadata for all genes in REL606 genome (named, assigned a uniprot ID consistent with E. coli K12)\n",
    "- Gene list for panther: name, uniprot ID for all genes which match a record in the Panther database (to use as a reference for gene set enrichment analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import re\n",
    "from Bio import pairwise2\n",
    "import time\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anuraglimdi/Desktop/TnSeq_Paper/LTEE-TnSeq_Paper/Metadata/Metadata_compilation\n"
     ]
    }
   ],
   "source": [
    "#current working directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anuraglimdi/Desktop/TnSeq_Paper/LTEE-TnSeq_Paper\n"
     ]
    }
   ],
   "source": [
    "#use the pathlib.Path function to get the parent directories-> goal is to navigate to directory with the metadata\n",
    "# and the breseq output data\n",
    "path = pathlib.Path(cwd)\n",
    "print(path.parents[1]) #this should be the base directory for the github repository: the exact path will differ for \n",
    "#each unique user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel606_locations = np.loadtxt('CDS_locations_NC_012967.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name NC_012967.1, 4419 features\n",
      "Seq('AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAG...TTC')\n"
     ]
    }
   ],
   "source": [
    "gb_file = \"K12_annotations/PROKKA_03162021.gbk\"\n",
    "gb_record = SeqIO.read(open(gb_file,\"r\"), \"genbank\")\n",
    "print(\"Name %s, %i features\" % (gb_record.name, len(gb_record.features)))\n",
    "print(repr(gb_record.seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some regular expression practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gene=thrA] [locus_tag=b0002] [db_xref=UniProtKB/Swiss-Prot:P00561] [protein=fused aspartate kinase/homoserine dehydrogenase 1] [protein_id=AAC73113.1][location=337..2799] [gbkey=CDS]\n",
      "thrA\n",
      "b0002\n",
      "P00561\n",
      "fused aspartate kinase/homoserine dehydrogenase 1\n"
     ]
    }
   ],
   "source": [
    "gb_feature = gb_record.features[1]\n",
    "string = gb_feature.qualifiers[\"product\"][0]\n",
    "print(string)\n",
    "#search for the gene name:\n",
    "print(re.search(\"\\[gene=(.+?)\\]\",string).group(1))\n",
    "#searching for locus tag:\n",
    "print(re.search(\"\\[locus_tag=(.+?)\\]\",string).group(1))\n",
    "#searching for uniprot ID:\n",
    "print(re.search(\"Swiss-Prot:(.+?)\\]\",string).group(1))\n",
    "#searching for protein product info\n",
    "print(re.search(\"\\[protein=(.+?)\\]\",string).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coordinates of the genes in the rel606 reference genome (automatically annotated by NCBI)\n",
    "genes_left = rel606_locations[:,0]\n",
    "genes_right = rel606_locations[:,1]\n",
    "gene_coords = np.concatenate((genes_left,genes_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prokka output genbank file has a few different formats for storing the information about the genes and the protein it codes for. Here, I'm going to try and count all the different cases that are of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "case1 = 0\n",
    "case2 = 0\n",
    "case3 = 0\n",
    "case3a = 0\n",
    "case4 = 0\n",
    "case4a = 0\n",
    "case5 = 0\n",
    "rest = 0\n",
    "#iterating over all features in the genbank file\n",
    "#starting from 1 as the first feature is just about the lenght of the genome and so on\n",
    "for i in range(1,len(gb_record.features)):\n",
    "    gb_feature = gb_record.features[i]\n",
    "    #gene on forward strand\n",
    "    if gb_feature.strand == 1:\n",
    "        start = gb_feature.location.nofuzzy_start+1\n",
    "        end = gb_feature.location.nofuzzy_end\n",
    "    #gene on reverse strand\n",
    "    elif gb_feature.strand == -1:\n",
    "        end = gb_feature.location.nofuzzy_start+1\n",
    "        start = gb_feature.location.nofuzzy_end\n",
    "    \n",
    "    #searching for the start or end coordinates in the gene_coords array:\n",
    "    if start in gene_coords or end in gene_coords:\n",
    "        count+=1\n",
    "        if 'gene' in gb_feature.qualifiers:\n",
    "            case1+=1\n",
    "        elif 'note' not in gb_feature.qualifiers and 'product' in gb_feature.qualifiers:\n",
    "            if gb_feature.qualifiers[\"product\"][0]=='hypothetical protein':\n",
    "                case2+=1\n",
    "            elif \"pseudo=true\" not in gb_feature.qualifiers[\"product\"][0]:\n",
    "#                 print(gb_feature.qualifiers)\n",
    "#                 print('\\n')\n",
    "                case3+=1\n",
    "            else:\n",
    "                case3a+=1\n",
    "        elif 'note' in gb_feature.qualifiers:\n",
    "            if 'product' in gb_feature.qualifiers:\n",
    "                case4+=1\n",
    "#                 print(gb_feature.qualifiers[\"product\"])\n",
    "#                 print('\\n')\n",
    "                if gb_feature.qualifiers[\"product\"]==['hypothetical protein']:\n",
    "                    case4a+=1\n",
    "                \n",
    "            else:\n",
    "                case5+=1\n",
    "        else:\n",
    "            rest+=1\n",
    "#             print(gb_feature.qualifiers)\n",
    "#             print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genes where annotation has /gene\n",
      "37\n",
      "genes coding for hypothetical proteins, no info included\n",
      "175\n",
      "genes coding for known proteins, info included in /product tag\n",
      "3584\n",
      "genes coding for known proteins, potentially pseudogene, info included in /product tag\n",
      "8\n",
      "genes coding for proteins, info included in /note tag\n",
      "222\n",
      "genes coding for hypothetical proteins, info in /note tag\n",
      "222\n",
      "genes with /note tag only\n",
      "0\n",
      "everything else\n",
      "0\n",
      "total\n",
      "4026\n"
     ]
    }
   ],
   "source": [
    "print(\"genes where annotation has /gene\")\n",
    "print(case1)\n",
    "print(\"genes coding for hypothetical proteins, no info included\")\n",
    "print(case2)\n",
    "print(\"genes coding for known proteins, info included in /product tag\")\n",
    "print(case3)\n",
    "print(\"genes coding for known proteins, potentially pseudogene, info included in /product tag\")\n",
    "print(case3a)\n",
    "print(\"genes coding for proteins, info included in /note tag\")\n",
    "print(case4)\n",
    "print(\"genes coding for hypothetical proteins, info in /note tag\")\n",
    "print(case4a)\n",
    "print(\"genes with /note tag only\")\n",
    "print(case5)\n",
    "print(\"everything else\")\n",
    "print(rest)\n",
    "print(\"total\")\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of genbank records in the prokka outputted file:\n",
    "- type 1: contains a /gene tag:\n",
    "- type 2: /note absent, /product is hypothetical protein\n",
    "- type 3: /note absent, /product is a known, characterized protein\n",
    "- type 4: /note present, /product is hypothetical protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the information from the genbank file which was annotated based on the gene names in e coli k12\n",
    "genes_start = []\n",
    "genes_end = []\n",
    "strand = []\n",
    "names = []\n",
    "uniprot_ids = []\n",
    "k12_locus_ids = []\n",
    "prokka_locus_ids = []\n",
    "protein_product = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "#iterating over all features in the genbank file\n",
    "#starting from 1 as the first feature is just about the lenght of the genome and so on\n",
    "for i in range(1,len(gb_record.features)):\n",
    "    gb_feature = gb_record.features[i]\n",
    "    #gene on forward strand\n",
    "    if gb_feature.strand == 1:\n",
    "        start = gb_feature.location.nofuzzy_start+1\n",
    "        end = gb_feature.location.nofuzzy_end\n",
    "    #gene on reverse strand\n",
    "    elif gb_feature.strand == -1:\n",
    "        end = gb_feature.location.nofuzzy_start+1\n",
    "        start = gb_feature.location.nofuzzy_end\n",
    "    \n",
    "    #searching for the start or end coordinates in the gene_coords array:\n",
    "    if start in gene_coords or end in gene_coords:\n",
    "        count+=1\n",
    "        #check for type 1:\n",
    "        if 'gene' in gb_feature.qualifiers:\n",
    "            names.append(gb_feature.qualifiers[\"gene\"][0])\n",
    "            k12_locus_ids.append('N/A')\n",
    "            prokka_locus_ids.append(gb_feature.qualifiers['locus_tag'])\n",
    "            #check if the uniprot ID for gene is present in the inference tag\n",
    "            if \"UniProtKB\" in gb_feature.qualifiers['inference'][1]:\n",
    "                uniprot_ids.append(re.search(\"UniProtKB:(.+)\",gb_feature.qualifiers[\"inference\"][1]).group(1))\n",
    "            else:\n",
    "                #if the inference was done using HMMER or something else, there's no related uniprot info\n",
    "                uniprot_ids.append('N/A')\n",
    "                \n",
    "            protein_product.append(gb_feature.qualifiers[\"product\"])\n",
    "            \n",
    "            #coordinate info\n",
    "            \n",
    "            genes_start.append(start)\n",
    "            genes_end.append(end)\n",
    "            strand.append(gb_feature.strand)\n",
    "        \n",
    "        elif 'note' not in gb_feature.qualifiers and 'product' in gb_feature.qualifiers:\n",
    "            #next, type 2: hypothetical protein with basically no info about it\n",
    "            if gb_feature.qualifiers[\"product\"][0]=='hypothetical protein':\n",
    "                #if there's no information about the name of the protein, I'll just put in the locus tag\n",
    "                names.append(gb_feature.qualifiers['locus_tag'][0])\n",
    "                k12_locus_ids.append('N/A')\n",
    "                prokka_locus_ids.append(gb_feature.qualifiers['locus_tag'])\n",
    "                uniprot_ids.append('N/A')\n",
    "                protein_product.append(gb_feature.qualifiers[\"product\"])                \n",
    "                \n",
    "                #coordinate info\n",
    "            \n",
    "                genes_start.append(start)\n",
    "                genes_end.append(end)\n",
    "                strand.append(gb_feature.strand)\n",
    "                \n",
    "            # type3: if the product tag is something other than hypothetical\n",
    "            # and if the gene isn't potentially a pseudogene \n",
    "            elif \"pseudo=true\" not in gb_feature.qualifiers[\"product\"][0]:\n",
    "                string = gb_feature.qualifiers[\"product\"][0]\n",
    "                #now for the regex magic\n",
    "                \n",
    "                #NAME SEARCH\n",
    "                names_search = re.search(\"\\[gene=(.+?)\\]\",string)\n",
    "                if names_search == None:\n",
    "                    names.append(gb_feature.qualifiers['locus_tag'][0])\n",
    "                else:\n",
    "                    names.append(re.search(\"\\[gene=(.+?)\\]\",string).group(1))\n",
    "                \n",
    "                #K12 LOCUS SEARCH\n",
    "                k12_locus_search = re.search(\"\\[locus_tag=(.+?)\\]\",string)\n",
    "                if k12_locus_search == None:\n",
    "                    k12_locus_ids.append('N/A')\n",
    "                else:\n",
    "                    k12_locus_ids.append(re.search(\"\\[locus_tag=(.+?)\\]\",string).group(1))\n",
    "                    \n",
    "                prokka_locus_ids.append(gb_feature.qualifiers['locus_tag'])\n",
    "                \n",
    "                #UNIPROT SEARCH\n",
    "                uniprot_search = re.search(\"Swiss-Prot:(.+?)\\]\",string)\n",
    "                if uniprot_search == None:\n",
    "                    uniprot_ids.append(\"N/A\")\n",
    "                else:\n",
    "                    uniprot_ids.append(re.search(\"Swiss-Prot:(.+?)\\]\",string).group(1))\n",
    "                \n",
    "                #PROTEIN SEARCH\n",
    "                protein_search = re.search(\"\\[protein=(.+?)\\]\",string)\n",
    "                if protein_search == None:\n",
    "                    protein_product.append(gb_feature.qualifiers['product'])\n",
    "                else:\n",
    "                    protein_product.append(re.search(\"\\[protein=(.+?)\\]\",string).group(1))\n",
    "                    \n",
    "                #coordinate info\n",
    "            \n",
    "                genes_start.append(start)\n",
    "                genes_end.append(end)\n",
    "                strand.append(gb_feature.strand)\n",
    "         \n",
    "        elif 'note' in gb_feature.qualifiers and 'product' in gb_feature.qualifiers:\n",
    "            string = gb_feature.qualifiers[\"note\"][0]\n",
    "            if \"pseudo=true\" not in string:\n",
    "                #NAME SEARCH\n",
    "                names_search = re.search(\"\\[gene=(.+?)\\]\",string)\n",
    "                if names_search == None:\n",
    "                    names.append(gb_feature.qualifiers['locus_tag'][0])\n",
    "                else:\n",
    "                    names.append(re.search(\"\\[gene=(.+?)\\]\",string).group(1))\n",
    "                    \n",
    "                #K12 LOCUS SEARCH\n",
    "                k12_locus_search = re.search(\"\\[locus_tag=(.+?)\\]\",string)\n",
    "                if k12_locus_search == None:\n",
    "                    k12_locus_ids.append('N/A')\n",
    "                else:\n",
    "                    k12_locus_ids.append(re.search(\"\\[locus_tag=(.+?)\\]\",string).group(1))\n",
    "                    \n",
    "                prokka_locus_ids.append(gb_feature.qualifiers['locus_tag'])\n",
    "                \n",
    "                #UNIPROT LOCUS SEARCH\n",
    "                uniprot_search = re.search(\"Swiss-Prot:(.+?)\\]\",string)\n",
    "                if uniprot_search == None:\n",
    "                    uniprot_ids.append(\"N/A\")\n",
    "                else:\n",
    "                    uniprot_ids.append(re.search(\"Swiss-Prot:(.+?)\\]\",string).group(1))\n",
    "                    \n",
    "                #PROTEIN SEARCH\n",
    "                protein_search = re.search(\"\\[protein=(.+?)\\]\",string)\n",
    "                if protein_search == None:\n",
    "                    protein_product.append(gb_feature.qualifiers['product'])\n",
    "                else:\n",
    "                    protein_product.append(re.search(\"\\[protein=(.+?)\\]\",string).group(1))\n",
    "                \n",
    "                #coordinate info\n",
    "            \n",
    "                genes_start.append(start)\n",
    "                genes_end.append(end)\n",
    "                strand.append(gb_feature.strand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(genes_end)-np.array(genes_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appears that I have successfully extracted all the information for ~4000 genes. Now, I need to compare the data with panther db text file and update either the name of the gene or the uniprot ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "panther_db = pd.read_csv(\"pantherGeneList.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ycgB'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\";(.+);\", panther_db.iloc[0,1]).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "panther_gene_names = []\n",
    "panther_uniprot_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range((panther_db.shape[0])):\n",
    "    temp1 = re.search(\"UniProtKB=(.+)\", panther_db.iloc[i,0]).group(1)\n",
    "    temp2 = re.search(\";(.+);\", panther_db.iloc[i,1]).group(1)\n",
    "    panther_gene_names.append(temp2)\n",
    "    panther_uniprot_ids.append(temp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll iterate through all the genes in the prokka annotated genome and see if they're present in either the panther uniprot list or gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_name = {}\n",
    "update_uniprot = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higA1 P9WJA7 1369\n",
      "queH Q7VYQ1 1406\n",
      "wbbD Q03084 1783\n",
      "vioB Q9XCW3 1788\n",
      "gpFI Q02TE1 1836\n",
      "kpsD Q03961 2622\n",
      "kpsM P23889 2630\n",
      "xcpW Q00517 2634\n",
      "epsH P45774 2636\n",
      "hypBA1 E8MGH8 3231\n",
      "sadB Q8ZL65 3252\n",
      "ehaG Q7DJ60 3253\n",
      "aglB Q9AGA6 3341\n",
      "salL A4X3Q0 3455\n",
      "atzF Q936X2 3474\n",
      "nicS Q88FX7 3840\n",
      "cybC P0ABE7 3866\n",
      "hpaB Q57160 3962\n",
      "hpcD Q05354 3967\n",
      "hpcB Q05353 3968\n",
      "hpcE P37352 3970\n",
      "farR P0DPR8 3971\n"
     ]
    }
   ],
   "source": [
    "both_in_db = 0\n",
    "gene_in_db = 0\n",
    "uniprot_in_db = 0\n",
    "neither = 0\n",
    "known_not_k12 = 0\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if names[i] in panther_gene_names and uniprot_ids[i] in panther_uniprot_ids:\n",
    "        both_in_db+=1\n",
    "    elif names[i] not in panther_gene_names and uniprot_ids[i] in panther_uniprot_ids:\n",
    "        uniprot_in_db +=1\n",
    "        #adding key-val pairs to the dictionary\n",
    "        update_name[names[i]] = panther_gene_names[panther_uniprot_ids.index(uniprot_ids[i])]\n",
    "    elif names[i] in panther_gene_names and uniprot_ids[i] not in panther_uniprot_ids:\n",
    "        gene_in_db +=1\n",
    "        #adding key-val pairs to the dictionary\n",
    "        update_uniprot[uniprot_ids[i]] = panther_uniprot_ids[panther_gene_names.index(names[i])]\n",
    "    else:\n",
    "        neither +=1\n",
    "        if \"FJKNNBLA\" not in names[i] and \"N/A\" not in uniprot_ids[i]:\n",
    "            print(names[i],uniprot_ids[i], i)\n",
    "            known_not_k12+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691\n",
      "109\n",
      "13\n",
      "204\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(both_in_db)   #both the gene name and uniprot is consistent with Panther DB\n",
    "print(uniprot_in_db) #only uniprot is found in panther DB\n",
    "print(gene_in_db) #only gene name is found in panther DB\n",
    "print(neither) #no match to the panther DB\n",
    "print(known_not_k12) #known genes, not present in K-12 and hence missing from the GO database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing all this, there are ~3800 genes in the genome that are also present in the panther DB. This is great, as we can be way more confident in any gene ontology analysis. Only around ~200 genes are left out of analysis as there are no annotations to the K12 genome that they map to (compared to ~1400 earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I'm going to update the names/uniprotIDs based on what is present in the panther db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name = names.copy()\n",
    "new_uniprot = uniprot_ids.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(names)):\n",
    "    if names[i] in panther_gene_names and uniprot_ids[i] in panther_uniprot_ids:\n",
    "        pass\n",
    "    elif names[i] not in panther_gene_names and uniprot_ids[i] in panther_uniprot_ids:\n",
    "        new_name[i] = panther_gene_names[panther_uniprot_ids.index(uniprot_ids[i])]\n",
    "    elif names[i] in panther_gene_names and uniprot_ids[i] not in panther_uniprot_ids:\n",
    "        new_uniprot[i] = panther_uniprot_ids[panther_gene_names.index(names[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_present = 0\n",
    "count_absent = 0\n",
    "for i in range(len(names)):\n",
    "    if new_name[i] not in panther_gene_names and new_uniprot[i] not in panther_uniprot_ids:\n",
    "        count_absent+=1\n",
    "    if new_name[i] in panther_gene_names and new_uniprot[i] in panther_uniprot_ids:\n",
    "        count_present+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "3813\n",
      "0.9492158327109783\n"
     ]
    }
   ],
   "source": [
    "print(count_absent)\n",
    "print(count_present)\n",
    "print(count_present/len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of the ~4000 genes in the REL606 genome, ~3800 have an well annotated equivalent in E. coli K12 (and also matching the GO Panther Database). ~180 of them are hypothetical proteins about which we don't really know much, and ~20 of them are genes which aren't annotated in the E. coli K12 genome.\n",
    "\n",
    "For the known but unannotated genes, if they turn out to be interesting from the standpoint of a differential essentiality analysis, I'll follow up on them then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the final metadata to file. \n",
    "\n",
    "In the current structure of the repository, the metadata will be one level above the current folder in which this Jupyter notebook is run.\n",
    "\n",
    "NOTE: There is no need to write to file, metadata already exists in the github repository. If you want to overwrite the existing files, uncomment the following code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidated metadata\n",
    "# with open(\"../all_metadata_REL606.txt\", 'w') as out:\n",
    "#     #first, writing the header\n",
    "#     out.write(\"Gene Name\\t Locus Tag (prokka_output)\\tLocus Tag (K12 reference)\\tStart of Gene\\tEnd of Gene\\tStrand\\tUniProt ID\\tProtein Product\\n\")\n",
    "#     for i in range(len(names)):\n",
    "#         out.write(f\"{new_name[i]}\\t{prokka_locus_ids[i][0]}\\t{k12_locus_ids[i]}\\t{genes_start[i]}\\t{genes_end[i]}\\t{strand[i]}\\t{new_uniprot[i]}\\t{protein_product[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene list file for running Panther (doing this as I want the comparison)\n",
    "# with open(\"../genelist_for_panther_REL606.txt\", 'w') as f:\n",
    "#     for i in range(len(names)):\n",
    "#         if new_name[i] in panther_gene_names and new_uniprot[i] in panther_uniprot_ids:\n",
    "#             f.write(f\"{new_uniprot[i]}\\t{new_name[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pd.read_csv(\"../all_metadata_REL606.txt\", sep=\"\\t\") #loading the data and examining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
